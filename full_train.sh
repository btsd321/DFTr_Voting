#!/bin/bash
# å®Œæ•´è®­ç»ƒè„šæœ¬ï¼ˆå¤šGPUåˆ†å¸ƒå¼è®­ç»ƒï¼‰
# åœ¨å¿«é€Ÿè°ƒè¯•æˆåŠŸåä½¿ç”¨

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source .venv/bin/activate

n_gpu=2  # ä½¿ç”¨çš„GPUæ•°é‡ï¼Œæ ¹æ®ä½ çš„ç¡¬ä»¶è°ƒæ•´
master_port=5235  # åˆ†å¸ƒå¼è®­ç»ƒç«¯å£

echo "ğŸš€ å¼€å§‹å®Œæ•´è®­ç»ƒï¼ˆ${n_gpu} GPUsï¼‰..."

# åˆ›å»ºå¿…è¦çš„ç›®å½•
mkdir -p train_log/MP6D/checkpoints
mkdir -p train_log/MP6D/train_info
mkdir -p train_log/MP6D/eval_results

# åˆ†å¸ƒå¼è®­ç»ƒ
python3 -m torch.distributed.launch \
    --nproc_per_node=$n_gpu \
    --master_port $master_port \
    train_mp6d.py \
    --gpus=$n_gpu \
    --gpu='0,1' \
    -lr 1e-2 \
    -epochs 1000

# å¦‚æœè¦ä»checkpointæ¢å¤è®­ç»ƒï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ï¼š
# --checkpoint="train_log/MP6D/checkpoints/FFB6D_epoch_XX.pth.tar"

echo "âœ… è®­ç»ƒå®Œæˆï¼"
echo "ğŸ“Š æŸ¥çœ‹è®­ç»ƒæ—¥å¿—: tensorboard --logdir train_log/MP6D/train_info"
echo "ğŸ’¾ æ¨¡å‹ä¿å­˜åœ¨: train_log/MP6D/checkpoints/"
